---
id: 79317
title: History
date: '2023-01-27T10:46:00+00:00'
author: 'Stephen Darlington'
excerpt: 'Why do people always think that the previous developers were stupid?'
layout: post
guid: 'https://www.zx81.org.uk/?p=79317'
aliases: ['/computing/opinion/history.html']
categories:
    - Opinion
tags:
    - Computing
    - engineering
    - history
    - Opinion
    - Software
    - twitter
    - work
---

<span style="font-size: revert;">A few years ago I had a job where every new recruit would go through a long process of shock and gradual acclimatisation to the main software product.</span>

What it did doesn’t matter as much as how it was built: it was an application developed on top of a proprietary programming language and user interface designer. The reaction was always the same. Why? *Why*?! Why would you reinvent Visual Basic on Unix? Why would you inflict a programming language even worse than Basic on developers?<sup>[1](#fn1-26684 "see footnote")</sup>

The answer, it turns out, is that the original developers were idiots.

No, of course that’s not true. But if that’s the case, then why did almost every developer start from that point of view when they first arrived at the company?

That brings us to [Twitter](https://www.zx81.org.uk/computing/opinion/twitter.html) and its new owner. One of his first public proclamations is to declare that there are too many micro-services running, and, worse, most of do nothing useful! The reply-guys all agree and, between them, argue that it’s entirely possible to rebuild Twitter from the ground-up in weeks, possibly even a weekend if given enough pizza and Blue Bottle.

Were the original developers of Twitter also idiots?

I don’t know as much about Twitter’s architecture, but I’d be willing to bet that, no, they were also not stupid.

If it’s not the original developers, what does it say about the critic? It says that they see the complexity but not the nuance. They see the current state but they do not see any of the decisions that lead up the current system. They see complexity, but without understanding the whole problem domain they don’t see why that complexity exists.

In the case of my job, the software predated Visual Basic, which is a pretty good reason for not using it. It also had to work on Unix and be editable on client sites without extra tooling. By the time I worked there, it may have been *dated* but it was in production at many clients. It worked. Sure, it’s not how you’d architect it *now* but the decisions that led to the design did make sense.

If it’s dated, then why not rewrite it? [That has been covered many times before](https://www.joelonsoftware.com/2000/04/06/things-you-should-never-do-part-i/), but the short answer is that when you design it, you focus so much on the clean, new solution that you forget why you added the warts to the old system. The layers upon layers of fixes and enhancements represent real world experience. Those micro-services *are* there for a reason. Not understanding the reason doesn’t change that<sup>[2](#fn2-26684 "see footnote")</sup>.

This is not an argument against evolving the software, only that you should understand what you already have. Sometimes rewriting *can* be justified. Rationalising a bunch of micro-services *isn’t* always a ridiculous idea. But there’s an important difference between [complex and complicated](https://deprogrammaticaipsum.com/complex-vs-complicated/). Can you know which your inherited system is after a few days on the job?

<div class="footnotes">---

1. It was a stack-based language, along the lines of Forth and Postscript. Long time users could do amazing things with tiny amounts of code. I never quite got there. [↩︎](#fnr1-26684 "return to article")
2. Logical fallacy: argument from incredulity. [↩︎](#fnr2-26684 "return to article")

</div>